{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1 DNN 2020/21",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrewyqv3oWBR"
      },
      "source": [
        "#Dataset\n",
        "\n",
        "https://www.mimuw.edu.pl/~ciebie/gsn-2021-1.zip\n",
        "\n",
        "We have a dataset containing 10000 small `28px * 28px * 1bit` images. Every image consists of two classes of geometric shapes selected randomly from six classes:\n",
        "\n",
        "- squares (id = 0),\n",
        "- circles (id = 1),\n",
        "- triangles pointing: up (2), right (3), down (4), left(5).\n",
        "\n",
        "There are always ten shapes on every image, all of them are xor'ed. There is at least one shape of both selected classes on the image, so the maximum number of shapes of one class on single image is nine. \n",
        "\n",
        "The dataset is labeled in csv file:\n",
        "\n",
        "```\n",
        "name,squares,circles,up,right,down,left\n",
        "img_00000.png,0,0,0,4,0,6\n",
        "....\n",
        "```\n",
        "\n",
        "First $9000$ images are training data, while the last $1000$ images are validation data.\n",
        "\n",
        "Example 16 images:\n",
        "\n",
        "![ez](https://drive.google.com/uc?export=view&id=11YkRIDMX2wUxLuWy5aoGmnR31VYnIMnp)\n",
        "\n",
        "\n",
        "#Networks\n",
        "\n",
        "You should prepare two different networks:\n",
        "\n",
        "1. **Shape classification**: network outputs six numbers: probabilities of a class being found on the image (in at least one copy). Loss function is the sum of loglosses over all classes:\n",
        "$$J = -\\sum_{j=0}^5y_i*log(\\hat y_i)+(1-y_i)*log(1-\\hat y_i)$$ *Notation:* $y_i$ is a ground truth, $\\hat y_i$ is predicted probability of class $i$ on the image.\n",
        "2. **Geometic shapes counting**: network outputs $10$ probabilities for each class, representing different numbers of objects of this class on the image. So the network should have $60$ outputs. Outputs $0..9$ should sum up to $100\\%$, so outputs $10..19$, and so on. The loss function for the network is the sum of squared counting errors:\n",
        "$$J = \\sum_{i=0}^5 \\sum_{j=0}^9\\hat y_j^i (j - r^i)^2$$ *Notation:* $r^i$ is a ground truth, $\\hat y_j^i$ is predicted probability of $j$ figures of class $i$ on the image.\n",
        "\n",
        "#Additional metrics\n",
        "\n",
        "## Shape classification\n",
        "\n",
        "For the shape classification, we are interested in the fraction of examples correctly classified: two classes with the highest probabilities (no matter how small probabilities are) are the classes that a model predicts.\n",
        "\n",
        "Example:\n",
        "\n",
        "$$\\hat{y}=(0.05, 0.9,0.3,0.05,0.05,0.05,0.05), y=(0,1,1,0,0,0)$$ is a correct classification.\n",
        "\n",
        "#Figure counting\n",
        "\n",
        "For the figure counting we are interested in a fraction of images with all the figures correctly counted. The highest value within ten probabilities for any class points at the number of figures of this class predicted by the model.\n",
        "\n",
        "Example:\n",
        "\n",
        "$$\\hat{y}^s_0 = 0.1, \\hat{y}^s_1= 0.3, \\hat{y}^s_2 = 0.31, ...$$  model predicts two instances of the class $s$.\n",
        "\n",
        "#Augmentations\n",
        "\n",
        "We can rotate an image by 90, 180, and 270 degrees. We can also mirror it along X or Y-axis. **Note that augmentations change image labels**.\n",
        "\n",
        "#Networks\n",
        "\n",
        "Your solution should be implemented in pytorch. You should use only the following layers:\n",
        "\n",
        "- dense\n",
        "- 2d convolution\n",
        "- dropout\n",
        "- batch normalization\n",
        "- max polling\n",
        "- reshape (for instance: flatten)\n",
        "\n",
        "For every network, prepare a short 2-page report explaining what architectures have you tested and what was the result. (Did dropout help? Did batch normalization help? How many layers have you been able to train successfully? Draw some plots.)\n",
        "\n",
        "\n",
        "#Scoring\n",
        "\n",
        "You should only use provided data. The list below shows the number of points corresponding to a subtask.\n",
        "\n",
        "- prepare augmentations for both networks (0.5)\n",
        "- prepare additional metrics (0.5)\n",
        "- prepare shape classification network (0.5)\n",
        "- prepare confusion matrix for classification and explain the results (0.5)\n",
        "- prepare figure counting network (0.5)\n",
        "- there are not too many possible different results of counting figures ${6 \\choose 2}9=135$. Prepare a network with 135 outputs. Compare its accuracy and loss with counting network's accuracy and loss. (0.5)\n",
        "- outstanding quality of the report (0 - average report, 1 - great report)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd6I0QVVoVVo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}